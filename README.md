# Text-Generation
This project explores the capabilities of text generation using LSTM (Long Short-Term Memory) and GPT (Generative Pre-trained Transformer) models. It involves training and evaluating both approaches on a similar dataset to understand their performance, strengths, and weaknesses in generating coherent and contextually relevant text.
